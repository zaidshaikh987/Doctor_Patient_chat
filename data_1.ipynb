{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MD.ZAID SHAIKH\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON saved successfully at medical_entities.json\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # General-purpose model\n",
    "\n",
    "def extract_medical_entities(text):\n",
    "    \"\"\"Extract medical terms using n-grams and keyword matching.\"\"\"\n",
    "    doc = nlp(text.lower())\n",
    "\n",
    "    # Define lowercase keyword sets\n",
    "    symptom_keywords = {\"dizziness\", \"palpitations\", \"fatigue\", \"nausea\", \"headache\", \"insomnia\", \"chronic pain\", \"muscle weakness\", \n",
    "    \"joint pain\", \"fever\", \"weight loss\", \"swelling\", \"cough\", \"shortness of breath\", \"chronic fatigue\", \"chest pain\", \n",
    "    \"difficulty breathing\", \"back pain\", \"blurred vision\", \"tingling\", \"sweating\", \"frequent urination\", \n",
    "    \"burning sensations while urinating\", \"light sensitivity\", \"lightheadedness\", \"loss of appetite\", \"rash\", \n",
    "    \"itching\", \"heartburn\", \"coughing up blood\", \"wheezing\", \"numbness\", \"throat pain\", \"muscle stiffness\", \n",
    "    \"night sweats\", \"nausea\", \"vomiting\", \"abdominal pain\", \"frequent sneezing\", \"hearing loss\", \"constipation\", \n",
    "    \"urinary incontinence\", \"dry mouth\", \"difficulty swallowing\", \"coughing blood\", \"hoarseness\", \"confusion\", \n",
    "    \"drowsiness\", \"cold hands or feet\", \"dysphagia\", \"difficulty walking\", \"tremors\", \"chills\", \"bloody stool\", \n",
    "    \"leg cramps\", \"weight gain\", \"hair loss\", \"abnormal vaginal bleeding\", \"difficulty concentrating\", \n",
    "    \"sore throat\", \"wheezing\", \"fatigue\", \"muscle cramps\", \"cough with sputum\", \"coughing up phlegm\", \n",
    "    \"diarrhea\", \"vomiting\", \"hypertension\", \"dehydration\", \"swollen ankles\", \"blurry vision\", \"insomnia\", \n",
    "    \"leg swelling\", \"poor circulation\", \"tiredness\", \"leg swelling\", \"anxiety\", \"depression\"}\n",
    "\n",
    "    condition_keywords = {\n",
    "        \"chronic obstructive pulmonary disease\", \"heart attack\", \"irritable bowel syndrome\", \"rheumatoid arthritis\", \n",
    "    \"urinary tract infection\", \"chronic fatigue syndrome\", \"psoriasis\", \"asthma\", \"diabetes\", \"hypertension\", \n",
    "    \"cancer\", \"liver disease\", \"kidney failure\", \"stroke\", \"dementia\", \"arthritis\", \"pneumonia\", \"sepsis\", \n",
    "    \"epilepsy\", \"gastroesophageal reflux disease\", \"multiple sclerosis\", \"alzheimer's disease\", \"parkinson's disease\", \n",
    "    \"systemic lupus erythematosus\", \"diabetic neuropathy\", \"tuberculosis\", \"obesity\", \"cystic fibrosis\", \"hepatitis\", \n",
    "    \"meningitis\", \"sickle cell anemia\", \"hiv/aids\", \"celiac disease\", \"ulcerative colitis\", \"crohn's disease\", \n",
    "    \"chronic kidney disease\", \"fibromyalgia\", \"autoimmune disease\", \"anemia\", \"leukemia\", \"pneumothorax\", \n",
    "    \"lupus\", \"tetanus\", \"scleroderma\", \"rheumatic fever\", \"prostate cancer\", \"ovarian cancer\", \"breast cancer\", \n",
    "    \"gastric cancer\", \"non-hodgkin lymphoma\", \"hemophilia\", \"vitiligo\", \"severe malaria\", \"bronchitis\", \"gout\", \n",
    "    \"scabies\", \"hemorrhoids\", \"varicose veins\", \"hemophilia\", \"eczema\", \"chronic pain\", \"melanoma\", \"hearing loss\", \n",
    "    \"menstrual disorders\", \"anxiety\", \"depression\", \"bipolar disorder\", \"schizophrenia\", \"ptsd\", \"dyslexia\", \n",
    "    \"insomnia\", \"phobia\", \"hysteria\", \"attention deficit disorder\", \"migraines\", \"chronic back pain\", \"obstructive sleep apnea\", \n",
    "    \"epistaxis\", \"otitis media\", \"sinusitis\", \"bronchial asthma\", \"copd\", \"hypothyroidism\", \"hyperthyroidism\", \n",
    "    \"gout\", \"rickets\", \"hyperlipidemia\", \"cystitis\", \"spondylitis\", \"vascular dementia\", \"strokes\", \"fibroids\"\n",
    "    }\n",
    "\n",
    "    medication_keywords = {\n",
    "        \"paracetamol\", \"ibuprofen\", \"aspirin\", \"metformin\", \"insulin\", \"atorvastatin\", \"omeprazole\", \"amoxicillin\", \n",
    "    \"losartan\", \"levothyroxine\", \"prednisone\", \"albuterol\", \"gabapentin\", \"sertraline\", \"amlodipine\", \"hydrochlorothiazide\", \n",
    "    \"clopidogrel\", \"lisinopril\", \"metoprolol\", \"simvastatin\", \"citalopram\", \"furosemide\", \"fluoxetine\", \"warfarin\", \n",
    "    \"trazodone\", \"cephalexin\", \"doxycycline\", \"rosuvastatin\", \"duloxetine\", \"pantoprazole\", \"hydrocodone\", \"tramadol\", \n",
    "    \"ciprofloxacin\", \"meloxicam\", \"escitalopram\", \"bupropion\", \"azithromycin\", \"ranitidine\", \"venlafaxine\", \"naproxen\", \n",
    "    \"ondansetron\", \"methotrexate\", \"mirtazapine\", \"spironolactone\", \"diazepam\", \"cyclobenzaprine\", \"diltiazem\", \n",
    "    \"metronidazole\", \"lorazepam\", \"morphine\", \"prednisolone\", \"famotidine\", \"baclofen\", \"clindamycin\", \"carvedilol\", \n",
    "    \"propranolol\", \"montelukast\", \"topiramate\", \"levofloxacin\", \"rivaroxaban\", \"apixaban\", \"cetirizine\", \n",
    "    \"diphenhydramine\", \"fentanyl\", \"hydroxyzine\", \"ivermectin\", \"ketorolac\", \"loratadine\", \"mefenamic acid\", \"methocarbamol\", \n",
    "    \"metformin xr\", \"metoclopramide\", \"nifedipine\", \"olmesartan\", \"phenytoin\", \"quetiapine\", \"risperidone\", \"sitagliptin\", \n",
    "    \"sulfasalazine\", \"tamsulosin\", \"terbinafine\", \"valacyclovir\", \"valsartan\", \"verapamil\", \"zolpidem\", \"tizanidine\", \n",
    "    \"clonazepam\", \"mometasone\", \"betamethasone\", \"fluticasone\", \"dexamethasone\", \"alprazolam\", \"acetaminophen\", \"esomeprazole\", \n",
    "    \"budesonide\", \"tiotropium\", \"cefuroxime\", \"erythromycin\", \"linezolid\", \"chlorpheniramine\"\n",
    "    } \n",
    "\n",
    "    # Generate n-grams (1-3 words)\n",
    "    words = [token.text for token in doc]\n",
    "    n_grams = []\n",
    "    for n in range(1, 4):\n",
    "        n_grams += [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "\n",
    "    symptoms = [term for term in n_grams if term in symptom_keywords]\n",
    "    conditions = [term for term in n_grams if term in condition_keywords]\n",
    "    medications = [term for term in n_grams if term in medication_keywords]\n",
    "\n",
    "    return list(set(symptoms)), list(set(conditions)), list(set(medications))\n",
    "\n",
    "file_path = r\"C:/Users/MD.ZAID SHAIKH/Documents/transcription.txt\"\n",
    "\n",
    "# Read the text content from the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "# Extract medical entities\n",
    "output_data = extract_medical_entities(text_content)\n",
    "\n",
    "# Convert the tuple to a dictionary with meaningful keys\n",
    "data_dict = {\n",
    "    \"symptoms\": output_data[0],\n",
    "    \"conditions\": output_data[1],\n",
    "    \"medications\": output_data[2]\n",
    "}\n",
    "\n",
    "json_file_path = \"medical_entities.json\"\n",
    "\n",
    "# Save to JSON file with correct format\n",
    "with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data_dict, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"JSON saved successfully at {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MD.ZAID SHAIKH\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "[SOAP Note]\n",
      "\n",
      "**Subjective (S):**\n",
      "\n",
      "*   Patient reports a headache for two days.\n",
      "*   Patient states they were advised to take Paracetamol.\n",
      "*   Patient is compliant and indicates they will remember the advice given (\"I will keep in mind the rest\").\n",
      "\n",
      "**Objective (O):**\n",
      "\n",
      "*   No objective clinical findings were reported. Further examination needed for detailed assessment.\n",
      "\n",
      "**Assessment (A):**\n",
      "\n",
      "*   Headache, etiology undetermined. Without further information, a specific diagnosis cannot be made. Differential diagnoses include tension headache, migraine, or headache secondary to other causes.\n",
      "\n",
      "**Plan (P):**\n",
      "\n",
      "*   Since patient was advised to take paracetamol, continue monitoring.\n",
      "*   Recommend further evaluation if the headache persists, worsens, or is accompanied by other symptoms (fever, stiff neck, vision changes, weakness, numbness, etc.).\n",
      "*   Encourage adequate hydration and rest.\n",
      "*   Further questioning about symptom characteristics needed to provide a more precise diagnosis and plan.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "\n",
    "def load_entities_from_json(json_path):\n",
    "    \"\"\"Load medical entities from JSON file\"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        return (data['symptoms'], data['conditions'], data['medications'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading entities: {e}\")\n",
    "        return ([], [], [])\n",
    "\n",
    "def generate_soap_with_gemini(transcription_path, entities_json_path):\n",
    "    \"\"\"Generate SOAP note using transcription file and entities JSON\"\"\"\n",
    "    try:\n",
    "        # Read transcription text\n",
    "        with open(transcription_path, 'r', encoding='utf-8') as f:\n",
    "            original_text = f.read()\n",
    "        \n",
    "        # Load entities from JSON\n",
    "        symptoms, conditions, medications = load_entities_from_json(entities_json_path)\n",
    "        \n",
    "        # Configure Google AI\n",
    "        genai.configure(api_key=\"AIzaSyDooyEJKTTh6Dwj7ntEDpBzlf50rzdEk-M\")\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "        \n",
    "        # Generate prompt\n",
    "        prompt = f\"\"\"\n",
    "        Generate structured SOAP note from:\n",
    "        Patient Statement: \"{original_text}\"\n",
    "        Identified Symptoms: {symptoms}\n",
    "        Medical Conditions: {conditions}\n",
    "        Current Medications: {medications}\n",
    "        \n",
    "        Format:\n",
    "        [SOAP Note]\n",
    "        Subjective (S): <patient-reported info>\n",
    "        Objective (O): <clinical findings>\n",
    "        Assessment (A): <diagnosis analysis>\n",
    "        Plan (P): <treatment plan>\n",
    "        \"\"\"\n",
    "        \n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error generating SOAP note: {e}\"\n",
    "\n",
    "# File paths (use raw strings for Windows paths)\n",
    "transcription_file = r\"C:/Users/MD.ZAID SHAIKH/Documents/transcription.txt\"\n",
    "entities_json = r\"C:/Users/MD.ZAID SHAIKH/Documents/AI_Medical_Assistant/backend/models/services/medical_entities.json\"\n",
    "\n",
    "# Generate and print SOAP note\n",
    "print(generate_soap_with_gemini(transcription_file, entities_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Empty term and query_key - nothing todo",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Example Usage\u001b[39;00m\n\u001b[0;32m     84\u001b[0m entities_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/MD.ZAID SHAIKH/Documents/AI_Medical_Assistant/backend/models/services/medical_entities.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_evidence_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentities_json\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[2], line 74\u001b[0m, in \u001b[0;36mgenerate_evidence_report\u001b[1;34m(json_path)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_evidence_report\u001b[39m(json_path):\n\u001b[0;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate evidence report\"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     articles \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_pubmed_evidence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Evidence Synthesis ðŸ“š\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, article \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(articles, \u001b[38;5;241m1\u001b[39m):\n",
      "Cell \u001b[1;32mIn[2], line 36\u001b[0m, in \u001b[0;36mfetch_pubmed_evidence\u001b[1;34m(json_path, max_results)\u001b[0m\n\u001b[0;32m     34\u001b[0m Entrez\u001b[38;5;241m.\u001b[39memail \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzaidshaikh98848@gmail.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m handle \u001b[38;5;241m=\u001b[39m Entrez\u001b[38;5;241m.\u001b[39mesearch(db\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpubmed\u001b[39m\u001b[38;5;124m\"\u001b[39m, term\u001b[38;5;241m=\u001b[39mquery, retmax\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[1;32m---> 36\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mEntrez\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Fetch articles\u001b[39;00m\n\u001b[0;32m     39\u001b[0m articles \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\MD.ZAID SHAIKH\\Lib\\site-packages\\Bio\\Entrez\\__init__.py:529\u001b[0m, in \u001b[0;36mread\u001b[1;34m(source, validate, escape, ignore_errors)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataHandler\n\u001b[0;32m    528\u001b[0m handler \u001b[38;5;241m=\u001b[39m DataHandler(validate, escape, ignore_errors)\n\u001b[1;32m--> 529\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m record\n",
      "File \u001b[1;32mc:\\Users\\MD.ZAID SHAIKH\\Lib\\site-packages\\Bio\\Entrez\\Parser.py:405\u001b[0m, in \u001b[0;36mDataHandler.read\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile should be opened in binary mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParseFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m expat\u001b[38;5;241m.\u001b[39mExpatError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mStartElementHandler:\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;66;03m# We saw the initial <!xml declaration, so we can be sure that\u001b[39;00m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;66;03m# we are parsing XML data. Most likely, the XML file is\u001b[39;00m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;66;03m# corrupted.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\a\\1\\s\\Modules\\pyexpat.c:477\u001b[0m, in \u001b[0;36mEndElement\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\MD.ZAID SHAIKH\\Lib\\site-packages\\Bio\\Entrez\\Parser.py:818\u001b[0m, in \u001b[0;36mDataHandler.endErrorElementHandler\u001b[1;34m(self, tag)\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_errors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(data)\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    820\u001b[0m value \u001b[38;5;241m=\u001b[39m ErrorElement(data, tag)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Empty term and query_key - nothing todo"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "\n",
    "# Configure Google Gemini\n",
    "genai.configure(api_key=\"AIzaSyDooyEJKTTh6Dwj7ntEDpBzlf50rzdEk-M\")\n",
    "\n",
    "def load_entities(json_path):\n",
    "    \"\"\"Load medical entities from JSON file\"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return {\n",
    "            'symptoms': data.get('symptoms', []),\n",
    "            'conditions': data.get('conditions', []),\n",
    "            'medications': data.get('medications', [])\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading entities: {e}\")\n",
    "        return {'symptoms': [], 'conditions': [], 'medications': []}\n",
    "\n",
    "def fetch_pubmed_evidence(json_path, max_results=3):\n",
    "    \"\"\"Fetch research based on JSON entities\"\"\"\n",
    "    entities = load_entities(json_path)\n",
    "    \n",
    "    # Build PubMed query\n",
    "    search_terms = []\n",
    "    search_terms += entities['symptoms']\n",
    "    search_terms += entities['conditions']\n",
    "    search_terms += [f\"{med} therapy\" for med in entities['medications']]\n",
    "    query = \" AND \".join(search_terms)\n",
    "\n",
    "    # PubMed API call\n",
    "    Entrez.email = \"zaidshaikh98848@gmail.com\"\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "    results = Entrez.read(handle)\n",
    "    \n",
    "    # Fetch articles\n",
    "    articles = []\n",
    "    for pubmed_id in results[\"IdList\"]:\n",
    "        with Entrez.efetch(db=\"pubmed\", id=pubmed_id, retmode=\"xml\") as handle:\n",
    "            article = handle.read()\n",
    "            articles.append(parse_article(article))\n",
    "    \n",
    "    return articles\n",
    "\n",
    "def parse_article(article_xml):\n",
    "    \"\"\"Extract article details from bytes XML\"\"\"\n",
    "    xml_str = article_xml.decode('utf-8')\n",
    "    title = \"\"\n",
    "    abstract = \"\"\n",
    "    \n",
    "    if \"<ArticleTitle>\" in xml_str and \"</ArticleTitle>\" in xml_str:\n",
    "        title = xml_str.split(\"<ArticleTitle>\")[1].split(\"</ArticleTitle>\")[0]\n",
    "    \n",
    "    if \"<AbstractText>\" in xml_str and \"</AbstractText>\" in xml_str:\n",
    "        abstract = xml_str.split(\"<AbstractText>\")[1].split(\"</AbstractText>\")[0]\n",
    "    \n",
    "    return {\n",
    "        'title': title,\n",
    "        'abstract': abstract\n",
    "    }\n",
    "\n",
    "def summarize_with_gemini(content):\n",
    "    \"\"\"Summarize using Google Gemini\"\"\"\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "    response = model.generate_content(\n",
    "        f\"Summarize this medical research in 2 sentences: {content}\"\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def generate_evidence_report(json_path):\n",
    "    \"\"\"Generate evidence report\"\"\"\n",
    "    articles = fetch_pubmed_evidence(json_path)\n",
    "    \n",
    "    report = \"âœ… Evidence Synthesis ðŸ“š\\n\"\n",
    "    for idx, article in enumerate(articles, 1):\n",
    "        summary = summarize_with_gemini(f\"{article['title']}. {article['abstract']}\")\n",
    "        report += f\"\\n{idx}. Title: {article['title']}\\n   Summary: {summary}\\n\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Example Usage\n",
    "entities_json = r\"C:/Users/MD.ZAID SHAIKH/Documents/AI_Medical_Assistant/backend/models/services/medical_entities.json\"\n",
    "print(generate_evidence_report(entities_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
